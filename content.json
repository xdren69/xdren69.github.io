{"pages":[{"title":"about","text":"WelcomeGlad to see you here. I will write down my insights about DL,NLP,Rsys in this place. Education 2015.09-2019.06 Software Engineering, Northwestern Polytechnical University 2020.09 Going to study at the National Cyber Security College of Wuhan University Research InterestDL，NLP，Recommend System Contect Email:","link":"/about/index.html"}],"posts":[{"title":"datawhale-零基础入门NLP-Task2","text":"学习目标对需要训练的数据进行分析，同时通过可视化了解待训练数据的特点 前半部分的代码是官方文档提供的；作业部分属于自己完成的 数据分析读入并观察数据的格式1234import pandas as pdtrain_df = pd.read_csv('../data/train_set.csv', sep='\\t')train_df.head() 分析每段文本的长度12345%pylab inlinetrain_df['text_len'] = train_df['text'].apply(lambda x: len(x.split(' ')))print(train_df.head())print(train_df['text_len'].describe()) 由此我们可以看到，对于所有文本，平均长度为907，最短为2，最长为57921 文本长度可视化分析123_ = plt.hist(train_df['text_len'], bins=200)plt.xlabel('Text char count')plt.title(\"Histogram of char count\") 由此我们可以看出文本长度的分布是不均匀的 文本类别可视化分析123train_df['label'].value_counts().plot(kind='bar')plt.title('News class count')plt.xlabel(\"category\") 由此我们可以看出，不同类别的文本数也是不同的，可能对模型的训练精度产生影响 单词频次分析先展示错误代码 12345678from collections import Counterall_lines = ' '.join(list(train_df['text']))word_count = Counter(all_lines.split(\" \"))word_count = sorted(word_count.items(), key=lambda d:d[1], reverse = True)print(len(word_count))print(word_count[0])print(word_count[-1]) 错误原因：在执行到第三行时会因内存占用太多而导致程序奔溃； 解决办法：将训练数据分批读入，而不是一次性全部读入 再展示正确代码 123456789101112from collections import Counterword_count = Counter()chunk_iterator = pd.read_csv('../data/train_set.csv',sep='\\t', chunksize=10000) for chunk in chunk_iterator: all_lines = ' '.join(list(chunk['text'])) word_count.update(all_lines.split(\" \"))word_count = sorted(word_count.items(), key=lambda d:d[1], reverse = True)print(len(word_count))print(word_count[0])print(word_count[-1]) 表明一共出现了6869个汉字，其中3750号汉字出现的次数最多，为7482224次；3133号汉字出现的次数最少，为1次 统计覆盖率最高的前三个单词 1234567891011121314from collections import Counter# 统计每个句子中出现的不同的单词，为每个句子构造一个单词集train_df['text_unique'] = train_df['text'].apply(lambda x: ' '.join(list(set(x.split(' ')))))# 将所有句子的单词集连接成文本all_lines = ' '.join(list(train_df['text_unique']))# 统计每个单词在单词集中出现的次数word_count = Counter(all_lines.split(\" \"))# 对统计结果进行排序word_count = sorted(word_count.items(), key=lambda d:int(d[1]), reverse = True)# 展示统计结果前三名，含义是每个单词在多少个句子中出现过print(word_count[0])print(word_count[1])print(word_count[2]) 表明：编号’3750’的单词出现在了197997个句子中；编号’900’的单词出现在了197653个句子中；编号’648’的单词出现在了191975个句子中 本章作业 假设字符3750，字符900和字符648是句子的标点符号，请分析赛题每篇新闻平均由多少个句子构成？ 12345678910111213# 可以直接套用前一段代码，统计这三个标点在所有文本中出现的总次数即可from collections import Counterword_count = Counter()chunk_iterator = pd.read_csv('../data/train_set.csv',sep='\\t', chunksize=10000) for chunk in chunk_iterator: all_lines = ' '.join(list(chunk['text'])) word_count.update(all_lines.split(\" \"))# 计算出总次数sum = word_count['3750']+word_count['900']+word_count['648']print(sum)# 计算出平均次数print(sum/200000.0) 统计每类新闻中出现次数对多的字符 1234567891011chunk_iterator = pd.read_csv('../data/train_set.csv',sep='\\t', chunksize=10000) for label in range(14): word_count = Counter() all_lines = '' for chunk in chunk_iterator: for index, l in enumerate(list(train_df['label'])): if l==label: all_lines = all_lines+' '+ train_df['text'][index] word_count.update(all_lines.split(\" \")) word_count = sorted(word_count.items(), key=lambda d:int(d[1]), reverse = True) print(label,word_count[0]) 引用[1] 提高python处理数据的效率方法 [2] Datawhale零基础入门NLP赛事 - Task2 数据读取与数据分析","link":"/2020/07/22/datawhale-NLP-t2/"},{"title":"datawhale-零基础入门NLP-Task5","text":"Introduction使用fastText之外的深度学习模型，例如word2vec、TextCNN、TextRNN，来完成文本分类任务 模型学习首先我们先学习一下我们即将使用的三种模型 word2vecTextCNN TextCNN利用CNN（卷积神经网络）进行文本特征抽取，不同大小的卷积核分别抽取n-gram特征，卷积计算出的特征图经过MaxPooling保留最大的特征值，然后将拼接成一个向量作为文本的表示。 TextRNN TextRNN利用RNN（循环神经网络）进行文本特征抽取，由于文本本身是一种序列，而LSTM天然适合建模序列数据。TextRNN将句子中每个词的词向量依次输入到双向双层LSTM，分别将两个方向最后一个有效位置的隐藏层拼接成一个向量作为文本的表示。 Reference[1] Datawhale零基础入门NLP赛事 - Task5-word2vec官方文档 [2] Datawhale零基础入门NLP赛事 - Task5-TextCNN官方文档 [3] Datawhale零基础入门NLP赛事 - Task5-TextRNN官方文档","link":"/2020/07/31/datawhale-NLP-t5/"},{"title":"Hexo+Icarus博客搭建记录","text":"个人感受我是一名前端小白，完全是跟着网上的教程走的，首先记录一下个人在看教程时的感受： 对整体架构不是很清楚，只能跟着教程一步一步摸索着走，遇到问题再google 找教程时要先看发布的时间，像Hexo和Icarus更新的挺快的，较早的教程是不适合现在的 不用跟着一个教程走到黑，可以看适合自己的部分，多找几个教程对比验证，就可以找到比较合适的实现方式了 网上关于这部分的教程说的已经很好很详细了，我就没必要造重复造轮子了，针对我自己（大神请忽略。。）一开始摸不着头脑的情况，我想先列出一个整体框架，让大家清楚自己每走一步都在那个阶段，并清楚下一阶段该做什么，我觉得这是比较有帮助的 整体架构这个blog搭建在github上的，使用了适用于个人blog的框架Hexo，Hexo的主题(theme)可由用户自定义(可以类比android的手机主题)，很多大神开源了很多主题，其中我选择的是Icarus，戳这里看demo 以上便是整体框架，接下来按照此可以划分出三步流程： 整体流程 在github上申请Repositories，并设置其为浏览器可访问的网页形式，具体教程可参照godweiyang在知乎的回答，PS：godweiyang自己改版了matery主题也很不错，大家也可以去看看他的主页，如果喜欢就可以一路跟着他在知乎的教程啦~ 安装并配置Hexo，具体教程同样可参照godweiyang在知乎的回答 安装好后，默认使用landscape主题，不过你现在已经可以尝试在此主题下写博客啦~PS：Hexo本身提供了标签、文章、归档等所有博客该有的功能，下一步的主题选择不影响当前编辑的内容的 此时需要先停下来，不着急进行下一步，先阅读Hexo的官方文档，PS：很短，官方文档是最直接了解这个框架功能的方式~，先了解一下怎么发文章，图片放在哪个目录下 在Hexo的基础上配置Icarus主题，完整过一遍Icarus的文档，建议阅读顺序如下： Icarus用户指南 - 主题配置对整体网站的配置 Icarus用户指南 - 挂件对于侧边栏的配置 随后运行整个网站，你会发现还有一些地方在报错，接下来就配置这些插件部分 做一些个性化改进： 图床配置，我是使用的腾讯云的COS服务，一开始会赠送6个月的服务，教程见这里 配置live2d看板娘（就是右手边的那只黑猫~），教程可以看这里 由于时间有限，不能改完所有bug使网站达到perfect，先记录下来，后期逐渐修改 bug(待修正)记录 个别渲染数学公式的格式不能使用的问题： 这是一个行内公式：\\(ax^2+bx+c=0\\)。 这是另一个行内公式：$ax^2+bx+c&gt;0$。 这是一个块状公式： $$\\displaystyle \\frac{1}{\\Bigl(\\sqrt{\\phi \\sqrt{5} }-\\phi\\Bigr) e^{\\frac25 \\pi} } = 1+\\frac{e^{-2\\pi} } {1+\\frac{e^{-4\\pi} } {1+\\frac{e^{-6\\pi} } {1+\\frac{e^{-8\\pi} } {1+\\cdots} } } }$$ 这是另一个块状公式： \\\\[f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)e^{2 \\pi i \\xi x}d\\xi\\\\] source12345678910111213 这是一个行内公式：\\\\(ax^2+bx+c=0\\\\)。 这是另一个行内公式：$ax^2+bx+c&gt;0$。 这是一个块状公式（注意一定用&lt;div&gt;包裹）： &lt;div&gt; $$\\displaystyle \\frac{1}{\\Bigl(\\sqrt{\\phi \\sqrt{5} }-\\phi\\Bigr) e^{\\frac25 \\pi} } = 1+\\frac{e^{-2\\pi} } {1+\\frac{e^{-4\\pi} } {1+\\frac{e^{-6\\pi} } {1+\\frac{e^{-8\\pi} } {1+\\cdots} } } }$$ &lt;/div&gt; 这是另一个块状公式： \\\\[f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)e^{2 \\pi i \\xi x}d\\xi\\\\] 以下为目前不能使用的 或者使用\\\\(\\LaTeX\\\\)环境： &lt;div&gt; \\\\begin{equation} A = \\\\begin{bmatrix} a &amp; b \\\\\\\\ c &amp; c \\\\end{bmatrix} \\\\end{equation} &lt;/div&gt;source1234567891011或者使用\\\\(\\LaTeX\\\\)环境：&lt;div&gt;\\\\begin{equation}A =\\\\begin{bmatrix}a &amp; b \\\\\\\\c &amp; c\\\\end{bmatrix}\\\\end{equation}&lt;/div&gt; busuanzi网站分析与live2d的看板娘冲突的问题 有人已提过issue，相关blog；由于加入live2d有两种实现方式，还有一种需要修改源码（官网推荐），教程yingchi’s blog navBar中的svg格式的logo不显示的问题（和footer用的是同一个logo，现在只有footer显示了） 有人已提过issue 给每一个页面加图片(optional) 最后欢迎大家评论与交流~","link":"/2020/06/25/how-to-build-a-blog/"},{"title":"整体认识——pytorch-learning（一）","text":"重要提醒：本文不求原创和创新，是基于哈工大SCIR实验室的大佬们写的这篇文章的补充和拓展，因此会合原文有许多重复之处，请大家注意！ 常用术语 iteration：表示1次迭代（也叫training step），每次迭代更新1次网络结构的参数，所需的数据量为1个batch的大小 batch-size：1次迭代所使用的样本量 epoch：1个epoch表示过了1遍训练集中的所有样本（包含多个batch的数据） 基本步骤我们首先将模型的训练过程分为四个步骤，分别是： 输入处理模块 (X 输入数据，变成网络能够处理的Tensor类型) 模型构建模块 (主要负责从输入的数据，得到预测的y^, 这就是我们经常说的前向过程) 定义代价函数和优化器模块 (注意，前向过程只会得到模型预测的结果，只有当前模块负责自动求导和参数更新) 构建训练过程（迭代训练过程，就是下图表情包的训练迭代过程） 以上1-4与下图1-4相互对应！ 详细解释一、数据处理对于数据处理，最为简单的⽅式就是将数据组织成为⼀个 。但许多训练需要⽤到mini-batch，直接组织成Tensor不便于我们操作。pytorch为我们提供了Dataset和Dataloader两个类来方便的构建。 torch.utils.data.Dataset 继承Dataset 类需要override 以下⽅法： 12345678910from torch utils. data import Dataset class trainDataset（Dataset）： def init （self）： # constructor def getitem （self, index）： # 获得第⊥ndex号的数据和标签 def len（self）： # 获得数据量 torch.utils.data.DataLoader 1torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False) DataLoader Batch。如果选择shuffle = True，每⼀个epoch 后，都会对所有数据打乱重新排序 mini-Batch batch_size 常⻅的使⽤⽅法如下： 123dataLoader Dataloader(dataset, shuffle=True, batch size=32)for i, data in enumerate (dataloader, 0) x, y # data同时获得数据和标签 shuffle=true表示每次取一个batch的数据前，先进行排序。官方注解如下： shuffle (bool, optional) – set to True to have the data reshuffled at every epoch (default: False). 二、模型构建所有的模型都需要继承torch.nn.Module ， 需要实现以下⽅法： 12345678class MyModel(torch, nn.Module)： def init(self)： super(MyModel, self).__init__() def forward(self, x)： return model=MyModel() 其中forward() ⽅法是前向传播的过程。在实现模型时，我们不需要考虑反向传播。 三、 定义代价函数和优化器主要负责自动求导和参数更新，也就是反向传播部分 12criterion = torch.nn.BCELOSS(reduction='sum') # 代价函数optimizer = torch.optim.Adam(model, parameters(), lr=0.0001, betas=(0.9，0.999), eps=1e-08, weight_decay=0, amsgrad=False) # 优化器 其中反向传播的基础：计算图，如下所示： 由图可以看出，全局偏导是由局部偏导根据链式法则，连续相乘而得出的 四、构建训练过程12345678def train(epoch)：#一个epoc的训练 for i, data in enumerate(dataLoader, 0): x,y = data #取出 minibatch数据和标签y pred = mode1(x) #前向传播 loss = criterion(y_pred,y) #计算代价函数 optimizer.zero_grad（）#清零梯度准备计算 1oss.backward（）#反向传播 optimizer.step（）#更新训练参数 引用[1] 推荐给大家！Pytorch编写代码基本步骤思想_哈工大SCIR实验室的大佬们写的 [2] 河北工业大学刘洪普老师的视频教程","link":"/2020/08/01/pytorch-learning-1/"},{"title":"线性回归——pytorch-learning（二）","text":"线性模型假设我们的线性模型的格式为： $$\\hat{y}=x * \\omega$$ 先确定优化目标，也就是cost function，我们算则MSE（Mean Square Error） $$\\cos t=\\frac{1}{N} \\sum_{n=1}^{N}\\left(\\hat{y}_{n}-y_{n}\\right)^{2}$$ 12345678910111213141516171819202122232425262728import numpy as npimport matplotlib.pyplot as pltx_data = [1.0, 2.0, 3.0]y_data = [2.0, 4.0, 6.0]# 前向传播def forward(x):return x * w# 计算loss，评价模型def loss(x, y):y_pred = forward(x)return (y_pred - y) * (y_pred - y)w_list = []mse_list = []for w in np.arange(0.0, 4.1, 0.1): #对参数进行穷举 print('w=', w) l_sum = 0 for x_val, y_val in zip(x_data, y_data): y_pred_val = forward(x_val) loss_val = loss(x_val, y_val) l_sum += loss_val print('\\t', x_val, y_val, y_pred_val, loss_val) print('MSE=', l_sum / 3) w_list.append(w) mse_list.append(l_sum / 3) 注：可以用visdom进行实时绘图，对数据进行可视化 梯度下降算法我们将寻找使目标函数值最小的参数的问题称为优化问题，为了代替对于参数的遍历方法，引入梯度下降算法 $$\\omega=\\omega-\\alpha \\frac{\\partial \\cos t}{\\partial \\omega}$$ 更新公式的方法 123456789101112131415161718192021222324252627x_data = [1.0, 2.0, 3.0]y_data = [2.0, 4.0, 6.0]w = 1.0def forward(x): return x * wdef cost(xs, ys): cost = 0 for x, y in zip(xs, ys): y_pred = forward(x) cost += (y_pred - y) ** 2 return cost / len(xs)def gradient(xs, ys): grad = 0 for x, y in zip(xs, ys): grad += 2 * x * (x * w - y) return grad / len(xs)print('Predict (before training)', 4, forward(4))for epoch in range(100): cost_val = cost(x_data, y_data) grad_val = gradient(x_data, y_data) w -= 0.01 * grad_val print('Epoch:', epoch, 'w=', w, 'loss=', cost_val)print('Predict (after training)', 4, forward(4)) 关于梯度下降，以上使用的是普通的梯度下降：即用所有数据的平均损失值来进行梯度更新；我们也可以使用SGD（Stochastic Gradient Descent）：即随机使用一个数据来更新梯度。SGD的好处是：单个样本包含了随机噪声，这样就避免停留在鞍点，缺点是：时间效率太低；因此现在主流是每次将训练数据分为过个batch，没经过一个batch进行一次数据更新 反向传播本质是构建计算图，以两层神经网络为例： $$\\hat{y}=W_{2}\\left(W_{1} \\cdot X+b_{1}\\right)+b_{2}$$ 其计算图为： pytorch基础 Tensor：一般针对每一个权重或中间变量使用一个tensor，其内部组成如下：包含权重本身和梯度（也是一个Tensor）两个部分 注意： 每进行一次反向传播，计算图就会被释放！ Tensor在做加法运算时会构建计算图；如过不进行backward()，就一直不会释放； Tensor中的梯度在.backward()方法执行后会被累加，所以每次在更新完梯度后都需要，将梯度清零 在进行计算时应使用w.grad.data，而不是w.grad（Tensor），否则会产生新的计算图 12345678910print(\"predict (before training)\", 4, forward(4).item())for epoch in range(100): for x, y in zip(x_data, y_data): l = loss(x, y) l.backward() #释放计算图，累加梯度 print('\\tgrad:', x, y, w.grad.item()) w.data = w.data - 0.01 * w.grad.data #更新梯度 w.grad.data.zero_() #梯度清零 print(\"progress:\", epoch, l.item())print(\"predict (after training)\", 4, forward(4).item()) 用pytorch实现线性回归123456789101112131415161718import torch# 准备数据x_data = torch.Tensor([[1.0], [2.0], [3.0]])y_data = torch.Tensor([[2.0], [4.0], [6.0]])# 设计计算图（根据上一篇）class LinearModel(torch.nn.Module): # 通过继承moudle，自动计算backword def __init__(self): super(LinearModel, self).__init__() self.linear = torch.nn.Linear(1, 1) # Class nn.Linear contain two member Tensors: weight and bias def forward(self, x): y_pred = self.linear(x) return y_predmodel = LinearModel() 关于torch.nn.Linear，官方文档如下： 优化目标函数MSE如下所示： 1criterion = torch.nn.MSELoss(size_average=False) 其中官方文档为： 迭代优化器如下所示： 12# 不继承于moudle，不会构建计算图optimizer = torch.optim.SGD(model.parameters(), lr=0.01) 通过model.parameters()，提取模型中所有需要更新的参数 接下来写训练过程 12345678for epoch in range(100): y_pred = model(x_data) loss = criterion(y_pred, y_data) print(epoch, loss) optimizer.zero_grad() loss.backward() optimizer.step() #更新 输出与测试 12345678# Output weight and biasprint('w = ', model.linear.weight.item())print('b = ', model.linear.bias.item())# Test Modelx_test = torch.Tensor([[4.0]])y_test = model(x_test)print('y_pred = ', y_test.data) 引用[1] 河北工业大学刘洪普老师的视频教程","link":"/2020/08/01/pytorch-learning-2/"},{"title":"Logistic回归与多分类问题——pytorch-learning（三）","text":"Logistic回归基本概念Logistic回归是将实数范围映射的值到[0,1]的范围内，虽然是回归模型，但是常被用作分类任务，理解成是否属于某一类别的概率，其映射又公式称为sigmoid函数，如下： $$\\sigma(x)=\\frac{1}{1+e^{-x}}$$ 优化的目标函数也应该相应做出改变，改为使用交叉熵函数cross-entropy，其含义是计算两个概率分布之间的差异性，越小越好，具体公式展示如下： $$H(p, q)=\\sum_{i} p\\left(x_{i}\\right) \\log \\frac{1}{\\log q\\left(x_{i}\\right)}=-\\sum_{i} p\\left(x_{i}\\right) \\log q\\left(x_{i}\\right)$$ 在二分类问题中，具体应用如下： $$\\operatorname{los} s=-(y \\log \\hat{y}+(1-y) \\log (1-\\hat{y}))$$ 代码展示123456789101112131415161718192021222324252627import torch.nn.functional as Fx_data = torch.Tensor([[1.0], [2.0], [3.0]])y_data = torch.Tensor([[0], [0], [1]])#-------------------------------------------------------#class LogisticRegressionModel(torch.nn.Module): def __init__(self): super(LogisticRegressionModel, self).__init__() self.linear = torch.nn.Linear(1, 1) def forward(self, x): y_pred = F.sigmoid(self.linear(x)) return y_pred model = LogisticRegressionModel()#-------------------------------------------------------#criterion = torch.nn.BCELoss(size_average=False)optimizer = torch.optim.SGD(model.parameters(), lr=0.01)#-------------------------------------------------------#for epoch in range(1000): y_pred = model(x_data) loss = criterion(y_pred, y_data) print(epoch, loss.item()) optimizer.zero_grad() loss.backward() optimizer.step() 多维特征值问题假设输入8维，输出1维 12345678910111213141516171819class Model(torch.nn.Module): def __init__(self): super(Model, self).__init__() ## 输入特征4维，输出特征1维 self.linear = torch.nn.Linear(4,2) ## 此时对同一组2维数据中的每一个取sigmoid self.sigmoid = torch.nn.Sigmoid() def forward(self, x): x1 = self.linear(x) print(x1) x2 = self.sigmoid(x1) print(x2) return x2model = Model()x_data = torch.Tensor([[1.0,2.0,3.0,4.0],[1.5,2.5,3.5,4.5]])y_predic = model(x_data) 结果如下： 如上所示，在多层神经网络中，一般利用torch.nn.Linear进行升维或降维，即： 将上图的神经网络实现成代码，如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243## 数据读取import numpy as npimport torch# 读取成numpy格式，注意一般gpu只接受32位，分隔符按照数据的内容自己选定xy = np.loadtxt('diabetes.csv.gz', delimiter=',', dtype=np.float32)# from_numpy可以自动转化为Tensor格式x_data = torch.from_numpy(xy[:,:-1])y_data = torch.from_numpy(xy[:, [-1]])## 设计网络class Model(torch.nn.Module): def __init__(self): super(Model, self).__init__() self.linear1 = torch.nn.Linear(8, 6) self.linear2 = torch.nn.Linear(6, 4) self.linear3 = torch.nn.Linear(4, 1) self.sigmoid = torch.nn.Sigmoid() def forward(self, x): x = self.sigmoid(self.linear1(x)) x = self.sigmoid(self.linear2(x)) x = self.sigmoid(self.linear3(x)) return x model = Model()## 构造损失和优化函数## 进行迭代for epoch in range(100): # Forward y_pred = model(x_data) loss = criterion(y_pred, y_data) print(epoch, loss.item()) # Backward optimizer.zero_grad() loss.backward() # Update optimizer.step() 以上代码有两个问题： 每个epoch计算的是全部的数据，而不是mini-batch的 目前的代码均只使用了sigmoid作为激活函数 接下来我们尝试解决这两个问题： 首先，用ReLu替换sigmoid作为激活函数： 123456789101112131415161718import torchclass Model(torch.nn.Module): def __init__(self): super(Model, self).__init__() self.linear1 = torch.nn.Linear(8, 6) self.linear2 = torch.nn.Linear(6, 4) self.linear3 = torch.nn.Linear(4, 1) self.relu = torch.nn.ReLU() self.sigmoid = torch.nn.Sigmoid() def forward(self, x): x = self.relu(self.linear1(x)) x = self.relu(self.linear2(x)) x = self.sigmoid(self.linear3(x)) return xmodel = Model() 注意：使用ReLu时，为防止最后的输出值被用来计算ln，所以最后一层用sigmoid作为激活函数 接下来，我们研究如何利用mini-batch来加载数据集 数据加载问题主要使用Dataset和DataLoader这两个工具，其中： Dataset：负责根据下标取出数据 DataLoader：负责取出mini-batch的小的数据 涉及的概念： iteration：表示1次迭代（也叫training step），每次迭代更新1次网络结构的参数，所需的数据量为1个batch的大小 batch-size：1次迭代所使用的样本量 epoch：1个epoch表示过了1遍训练集中的所有样本（包含多个batch的数据） 若总的数据量为1000，batch的大小为100，则每一次经过一次epoch，需要通过10次iteration 多分类问题引用[1] 河北工业大学刘洪普老师的视频教程","link":"/2020/08/01/pytorch-learning-3/"},{"title":"卷积神经网络——pytorch-learning（四）","text":"引用[1] 河北工业大学刘洪普老师的视频教程","link":"/2020/08/01/pytorch-learning-4/"},{"title":"datawhale-零基础入门NLP-Task3","text":"学习目标此次任务的目标是：在不同的文档表示方法下，使用传统机器学习算法来完成文本分类任务 文本表示方法(part1) 由于机器学习模型的输入只能是数字，而不是文本；所以在实现文本分类任务时，我们首先应该考虑的是如何将一段文本向量化 Bag of Words (AKA Count Vectors)用双城记来举例子展示我们是如何计算Bag of Words的 It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, 假设这四句话每一句都是一段文本，这四个文本共同组成了一个语料库 设计词典： 通过对以上的文本进行分析，我们可以得出语料库中一共出现了如下10个词语 1it、was、the、best、of、times、worst、age、wisdom、foolishness 计算出这段文本的向量表示，即将向量的长度设计为10，每一维度对应某个文本中一个单词出现的次数，即可以得到 1234\"It was the best of times\" = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\"it was the worst of times\" = [1, 1, 1, 0, 1, 1, 1, 0, 0, 0]\"it was the age of wisdom\" = [1, 1, 1, 0, 1, 0, 0, 1, 1, 0]\"it was the age of foolishness\" = [1, 1, 1, 0, 1, 0, 0, 1, 0, 1] 对这一算法的直观理解是：词汇分布越相似的文本，其含义越相近 TF-IDF根据这一算法的名字，我们将分成TF、DF、IDF三个小部分来介绍 我们的基本思想是：寻找一些词语，用这些词语来代表一个文本；这一算法多用在搜索引擎等技术中，用于搜索和待检查词语匹配的文章 根据日常经验，我们的基本思路是：寻找在一个文本中出现频率最高的几个词来代表这段文本，但是要排除停顿词，如英语中的“a, the, is, was”等 TF全名是Term Frequency，即词频。因为词频最能直观反映一篇文章的keywords，比如一篇写猫的文章，其中“猫”这个字的出现的次数一定很多。 由于有些文本是长文本，有些是短文本；就算同是写猫的文本，长文本中“猫”出现的次数一定多于短文本中“猫”出现的次数，但是却不能表明长文本中与“猫”的相关度比短文本强。因此我们在这里需要进行正则化，即： 1tf(t,d) = count of t in d / number of words in d DF全名是Document Frequency，即文档频率。这个词可不是它的字面意思哈！当我们计算一个单词A的DF时，实际上我们是在计算语料库中包含单词A的文档的数量。其公式如下： 1df(t) = occurrence of t in documents 我们之所以要计算DF，是为了用到它的倒数IDF，DF表明了一个单词的普遍程度，DF的值越大，表明当前单词在大部分的文章都出现过，十分普遍，不具备代表意义 IDF全名是Inverse Document Frequency，即逆文档频率，它就是DF的倒数。其含义已在DF中说过了，这里就说一下计算公式吧： $$\\operatorname{idf}(\\mathrm{t})=\\log (\\mathrm{N} /(\\mathrm{df}+1))$$ 之所以+1，是因为防止除数为0（在搜索系统中，待查询的词可能没在文本中出现过）；之所以取log，是因为防止数据爆炸（value explode） 综上， 一个词语的TF和IDF与这个词语在一段文本中是否具有代表性是正相关的，因此TF*IDF与这个词语也是正相关的；在实际文本中一般选择TF*IDF中最大的头几个词来代表文本 在本题中会将文本转化成一个长度固定为vocab_size的向量，每一维度对应着相应下标的单词的TF*IDF值 Trick: N-gram通过对以上两种算法的学习，我们发现这两种算法的需要构建词典来进行词频统计，在构建词典时，我们可以使用N-gram算法来扩充我们的词典，让词典中的一些词更有意义。N-gram是将连续的N个词组成一个新的词语来看待，基本思想将文本内容按照字节顺序进行大小为N的滑动窗口操作，最终形成长度为N的字节片段序列 举例而言，对于“It was the best of times”这句话使用2-gram（bigram）来分析，会在词典中增加这些单词： 1“it was”、“was the”、“the best”、“best of”、“of times” 以后在统计词频时，会将以上算作是一个单词来看待。 机器学习模型本次调用的是Ridge Classifier分类模型，是由岭回归（Ridge Regression）变化而来的，我们接下来先介绍岭回归。 线性回归用如下所示的线性模型，去拟合数据 $$\\hat{y}=w[0] \\times x[0]+w[1] \\times x[1]+\\ldots+w[n] \\times x[n]+b$$ 为了检测拟合结果，引入了代价函数（cost function），训练时代价越高，模型效果越差 $$\\sum_{i=1}^{M}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}=\\sum_{i=1}^{M}\\left(y_{i}-\\sum_{j=0}^{p} w_{j} \\times x_{i j}\\right)^{2}$$ 可能出现的结果： 训练集cost 测试集cost 模型效果 大 大 欠拟合（under fitting） 小 小 效果好 小 大 过拟合（over fitting） 岭回归（Ridge Regression） 本质是在线性回归的基础上加入了L2正则化 进行拟合的函数是不变的，变化的是代价函数（cost function）的计算方法 $$\\sum_{i=1}^{M}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}=\\sum_{i=1}^{M}\\left(y_{i}-\\sum_{j=0}^{p} w_{j} \\times x_{i j}\\right)^{2}+\\lambda \\sum_{j=0}^{p} w_{j}^{2}$$ 相当于在减小cost function的同时需要满足如下条件： $$\\text { For some } c&gt;0, \\sum_{j=0}^{p} w_{j}^{2}&lt;c$$ 即对模型中的参数的大小都进行了一定程度的抑制，通过$\\lambda$的值来控制抑制程度；$\\lambda$越接近0，就越接近普通的线性回归 注意：只能用来解决过拟合问题，不能用来筛选特征 Lasso回归 本质是在线性回归的基础上加入了L1正则化 $$\\sum_{i=1}^{M}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}=\\sum_{i=1}^{M}\\left(y_{i}-\\sum_{j=0}^{p} w_{j} \\times x_{i j}\\right)^{2}+\\lambda \\sum_{j=0}^{p}\\left|w_{j}\\right|$$ 相当于在减小cost function的同时需要满足如下条件： $$\\text { For some } t&gt;0, \\sum_{j=0}^{p}\\left|w_{j}\\right|&lt;t$$ 可以解决的问题： 筛选特征，会将无用的特征前的权重赋值为0 防止过拟合 ==对于欠拟合模型，适当减少$\\lambda$ ，并增加迭代次数，有助于减小cost的值== Ridge Classifier 本质是将Ridge Regression转化为一个多输出的回归，预测类对应回归的最高值输出 代码实现具体代码如下所示： Count Vectors + RidgeClassifier 12345678910111213141516import pandas as pdfrom sklearn.feature_extraction.text import CountVectorizerfrom sklearn.linear_model import RidgeClassifierfrom sklearn.metrics import f1_scoretrain_df = pd.read_csv('../data/train_set.csv', sep='\\t', nrows=15000)vectorizer = CountVectorizer(max_features=3000)train_test = vectorizer.fit_transform(train_df['text'])clf = RidgeClassifier()clf.fit(train_test[:10000], train_df['label'].values[:10000])val_pred = clf.predict(train_test[10000:])print(f1_score(train_df['label'].values[10000:], val_pred, average='macro')) TF-IDF + RidgeClassifier 12345678910111213141516import pandas as pdfrom sklearn.feature_extraction.text import TfidfVectorizerfrom sklearn.linear_model import RidgeClassifierfrom sklearn.metrics import f1_scoretrain_df = pd.read_csv('../data/train_set.csv', sep='\\t', nrows=15000)tfidf = TfidfVectorizer(ngram_range=(1,3), max_features=3000)train_test = tfidf.fit_transform(train_df['text'])clf = RidgeClassifier()clf.fit(train_test[:10000], train_df['label'].values[:10000])val_pred = clf.predict(train_test[10000:])print(f1_score(train_df['label'].values[10000:], val_pred, average='macro')) 引用[1] Datawhale零基础入门NLP赛事 - Task3官方文档 [2] A Gentle Introduction to the Bag-of-Words Model [3] TF-IDF from scratch in python on real world dataset. [4] Ridge and Lasso Regression: L1 and L2 Regularization","link":"/2020/07/25/datawhale-NLP-t3/"},{"title":"datawhale-零基础入门NLP-Task1","text":"题目理解目标是用多种思路完成天池的NLP新手级题目零基础入门NLP - 新闻文本分类，题目的大意是训练一个模型，对不同的文本段进行分类，分成财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐这十四个类（记作0-13），其中会对输入的文本段做匿名化处理，如下所示： 流程划分由于题目给出的训练用的文本段是匿名化的，无法进行分词操作，将整个比赛流程划分成特征提取和分类模型两个方面，因此在后续任务中会通过四种思路来完成这一题目，分别是： TF-IDF + 机器学习分类器 TF-IDF用于对文本提取特征 FastText FastText是入门款的词向量，由facebook提供 WordVec + 深度学习分类器 WordVec是进阶款的词向量 Bert词向量 Bert是高配款的词向量 测评指标评价标准为类别f1_score的均值，结果越大越好。 对于评测标准的理解评测标准的本质是用来筛选模型的好坏的，而模型的好坏在不同的条件下有不同的标准，因此评测标准也应该是多样的。 在本题中模型的作用是预测一段文本的类别，细化而言，即对于一段文本，判断其是否属于14类中的某一类（例如第3类），如果是模型预测是第3类就是positive，模型预测不是第3类就是negative，再结合实际情况，一共得到四类结果，如下图所示： 在实际中有很多种计算方式： Precision： 公式：$$Precision =\\frac{ True Positive }{ True Positive + False Positive }$$ 理解：这一标准关注的是对于某一类，在所有预测为positive的文本中，在实际中也是positive（即属于true positive）的概率 用途：Precision is a good measure to determine, when the costs of False Positive is high.（当分类器将一个实际negative的样本识别为positive会产生巨大损失时，即对false positive敏感，例如非垃圾邮件被识别成垃圾邮件） Recall： 公式：$$ Recall =\\frac{True Positive}{True Positive+False Negative}$$ 理解：这一标准关注的是对于某一类，在所有实际中为positive的文本中，在预测时也是positive（即属于true positive）的概率，也可以理解成模型对正样例的捕获能力 用途：Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative.（用于当一个正样例被分类错误会带来巨大损失的模型，即对false negative敏感，例如对强传染疾病的分类，将患病病人识别成不患病的） Accuracy： 公式：$$\\mathrm{Accuracy}=\\frac{\\text { True Positive }+\\text { True Negative }}{ \\text { (True Positive }+\\text { False Positive }+\\text { True Negative }+\\text { False Negative })}$$ 理解：计算的是所有样本中分类正确（不论正样例还是负样例）占算有样本的比例 用途：It is most used when all the classes are equally important.（用于所有分类结果都一样重要时） F1_score： 公式：$$\\mathrm{F} 1=\\left(\\frac{\\text { Recall }^{-1}+\\text {Precision }^{-1}}{2}\\right)^{-1} =2 \\times \\frac{ Precision*Recall} {Precision+Recall}$$ 理解：This is the harmonic mean of Precision and Recall and gives a better measure of the incorrectly classified cases than the Accuracy Metric（属于Precision和Recall的平衡点，即对Precision和Recall计算调和平均数） 对于F1_score和Accuracy的比较： Accuracy is used when the True Positives and True negatives are more important while F1-score is used when the False Negatives and False Positives are crucial Accuracy can be used when the class distribution is similar while F1-score is a better metric when there are imbalanced classes as in the above case. In most real-life classification problems, imbalanced class distribution exists and thus F1-score is a better metric to evaluate our model on. Purva HuilgolAccuracy vs. F1-Score 参考[1] Datawhale零基础入门NLP赛事 - Task1官方文档 [2] Accuracy, Precision, Recall or F1? [3] Accuracy vs. F1-Score [3] 图片引用自这里","link":"/2020/07/21/datawhale-NLP-t1/"},{"title":"datawhale-零基础入门NLP-Task4","text":"学习目标不同于之前使用传统的机器学习方法，此次任务使用深度学习方法fastText来解决文本分类问题 文本表示方法（part 2）之前的博客讨论了文本的表示方法： TF-IDF Bag of Words (AKA Count Vectors) 通过观察，我们可以发现它们存在一定的缺陷：每一段文本被表示所需的向量维度很大，两种方法均是vocab-size大小的；导致训练模型所需要的时间很长 于是我们思考用一种更加简短的方式来表达一段文本，于是想到了fastText模型，与之前的文本表示方法不同，其基本思想是将一个单词通过深度学习模型表示在一个更小维度的向量空间，然后将整个句子的词向量求和——由于使用了更小维度的向量空间，训练和预测都会变得更快！ fastText模型简介fastText与word2vec、Glove均是对单词进行embedding的一种方法，本此任务我们先介绍fastText，其他两种之后会进行介绍 首先我们介绍embedding相比较与传统的文本表示方法（TF-IDF、Bag of Words）的优点：从task3我们可以知道，传统的文本表示方法形成的向量大小是vocab-size的，比较看重的是这段文本在每一个单词（或字）上的权重大小；而embedding会将一段文本中的每个单词映射到一个更小的空间中，使得每一个维度都有其意义（比如一个维度表示颜色，另一个维度表示大小之类的），因此展示在向量空间中，文本向量的距离可以用来衡量文本间的语义相似程度 接下来，我们介绍fastText这一模型 fastText的核心思想是：使用character级别的N-gram（之前我们使用过单词级别的n-gram，即将一段文本中连续的n个单词组成一个新的词语），而这里使用的是字符级的N-gram，即将一个单词中连续的n个字符拆出来，形成一个行的单词，具体的例子为：对于单词“where”，在n=3时，形成的单词为：&lt;wh, whe, her, ere, re&gt;以及where，因此从某种角度而言，字符级别的N-gram也是扩充词库的一种重要方法 fastText与word2vec（下一篇博客中会使用）相比，有如下优点： 在word2vec中，我们并没有直接利用构词学中的信息。无论是在Skip-Gram模型还是Continuous Bag of Words (CBOW)模型中，我们都将形态不同的单词用不同的向量来表示。例如，“dog”和“dogs”分别用两个不同的向量表示，而模型中并未直接表达这两个向量之间的关系。鉴于此，fastText提出了子词嵌入（subword embedding）的方法，从而试图将构词信息引入word2vec中的跳字模型 ….与Skip-Gram模型相比，fastText中词典规模更大，造成模型参数更多，同时一个词的向量需要对所有子词向量求和，继而导致计算复杂度更高。但与此同时，较生僻的复杂单词，甚至是词典中没有的单词，可能会从同它结构类似的其他词那里获取更好的词向量表示 李沐动手学深度学习 用fastText方法进行文本分类的模型架构如下所示： 代码实现 环境配置： 为了完成本次实验，需要首先安装安装包：我用的是conda下配置的python环境，直接使用会报错，说需要安装Microsoft Visual C++ 14.0的依赖；因此推荐离线安装，具体推荐参考这里 具体代码实现如下： 1234567891011121314import pandas as pdfrom sklearn.metrics import f1_score# 转换为FastText需要的格式train_df = pd.read_csv('../data/train_set.csv', sep='\\t', nrows=15000)train_df['label_ft'] = '__label__' + train_df['label'].astype(str)train_df[['text','label_ft']].iloc[:-5000].to_csv('train.csv', index=None, header=None, sep='\\t')import fasttextmodel = fasttext.train_supervised('train.csv', lr=1.0, wordNgrams=2, verbose=2, minCount=1, epoch=25, loss=\"hs\")val_pred = [model.predict(x)[0][0].split('__')[-1] for x in train_df.iloc[-5000:]['text']]print(f1_score(train_df['label'].values[-5000:].astype(str), val_pred, average='macro')) 引用[1]","link":"/2020/07/27/datawhale-NLP-t4/"}],"tags":[{"name":"datawhale","slug":"datawhale","link":"/tags/datawhale/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"Hexo,Icarus","slug":"Hexo-Icarus","link":"/tags/Hexo-Icarus/"},{"name":"pytorch","slug":"pytorch","link":"/tags/pytorch/"}],"categories":[{"name":"Datawhale学习手记","slug":"Datawhale学习手记","link":"/categories/Datawhale%E5%AD%A6%E4%B9%A0%E6%89%8B%E8%AE%B0/"},{"name":"博客搭建","slug":"博客搭建","link":"/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"pytorch-learning","slug":"pytorch-learning","link":"/categories/pytorch-learning/"}]}