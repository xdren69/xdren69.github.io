{"pages":[{"title":"about","text":"WelcomeGlad to see you here. I will write down my insights about DL,NLP,Rsys in this place. Education 2015.09-2019.06 Software Engineering, Northwestern Polytechnical University 2020.09 Going to study at the National Cyber Security College of Wuhan University Research InterestDL，NLP，Recommend System Contect Email:","link":"/about/index.html"}],"posts":[{"title":"Hexo+Icarus博客搭建记录","text":"个人感受我是一名前端小白，完全是跟着网上的教程走的，首先记录一下个人在看教程时的感受： 对整体架构不是很清楚，只能跟着教程一步一步摸索着走，遇到问题再google 找教程时要先看发布的时间，像Hexo和Icarus更新的挺快的，较早的教程是不适合现在的 不用跟着一个教程走到黑，可以看适合自己的部分，多找几个教程对比验证，就可以找到比较合适的实现方式了 网上关于这部分的教程说的已经很好很详细了，我就没必要造重复造轮子了，针对我自己（大神请忽略。。）一开始摸不着头脑的情况，我想先列出一个整体框架，让大家清楚自己每走一步都在那个阶段，并清楚下一阶段该做什么，我觉得这是比较有帮助的 整体架构这个blog搭建在github上的，使用了适用于个人blog的框架Hexo，Hexo的主题(theme)可由用户自定义(可以类比android的手机主题)，很多大神开源了很多主题，其中我选择的是Icarus，戳这里看demo 以上便是整体框架，接下来按照此可以划分出三步流程： 整体流程 在github上申请Repositories，并设置其为浏览器可访问的网页形式，具体教程可参照godweiyang在知乎的回答，PS：godweiyang自己改版了matery主题也很不错，大家也可以去看看他的主页，如果喜欢就可以一路跟着他在知乎的教程啦~ 安装并配置Hexo，具体教程同样可参照godweiyang在知乎的回答 安装好后，默认使用landscape主题，不过你现在已经可以尝试在此主题下写博客啦~PS：Hexo本身提供了标签、文章、归档等所有博客该有的功能，下一步的主题选择不影响当前编辑的内容的 此时需要先停下来，不着急进行下一步，先阅读Hexo的官方文档，PS：很短，官方文档是最直接了解这个框架功能的方式~，先了解一下怎么发文章，图片放在哪个目录下 在Hexo的基础上配置Icarus主题，完整过一遍Icarus的文档，建议阅读顺序如下： Icarus用户指南 - 主题配置对整体网站的配置 Icarus用户指南 - 挂件对于侧边栏的配置 随后运行整个网站，你会发现还有一些地方在报错，接下来就配置这些插件部分 做一些个性化改进： 图床配置，我是使用的腾讯云的COS服务，一开始会赠送6个月的服务，教程见这里 配置live2d看板娘（就是右手边的那只黑猫~），教程可以看这里 由于时间有限，不能改完所有bug使网站达到perfect，先记录下来，后期逐渐修改 bug(待修正)记录 个别渲染数学公式的格式不能使用的问题： 这是一个行内公式：\\(ax^2+bx+c=0\\)。 这是另一个行内公式：$ax^2+bx+c&gt;0$。 这是一个块状公式： $$\\displaystyle \\frac{1}{\\Bigl(\\sqrt{\\phi \\sqrt{5} }-\\phi\\Bigr) e^{\\frac25 \\pi} } = 1+\\frac{e^{-2\\pi} } {1+\\frac{e^{-4\\pi} } {1+\\frac{e^{-6\\pi} } {1+\\frac{e^{-8\\pi} } {1+\\cdots} } } }$$ 这是另一个块状公式： \\[f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)e^{2 \\pi i \\xi x}d\\xi\\] source123456789101112131415这是一个行内公式：\\\\(ax^2+bx+c=0\\\\)。这是另一个行内公式：$ax^2+bx+c&gt;0$。这是一个块状公式（注意一定用&lt;div&gt;包裹）：&lt;div&gt;$$\\displaystyle \\frac{1}{\\Bigl(\\sqrt{\\phi \\sqrt{5} }-\\phi\\Bigr) e^{\\frac25 \\pi} } = 1+\\frac{e^{-2\\pi} } {1+\\frac{e^{-4\\pi} } {1+\\frac{e^{-6\\pi} } {1+\\frac{e^{-8\\pi} } {1+\\cdots} } } }$$&lt;/div&gt;这是另一个块状公式：\\\\[f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)e^{2 \\pi i \\xi x}d\\xi\\\\] 以下为目前不能使用的 或者使用\\(\\LaTeX\\)环境： \\\\begin{equation} A = \\\\begin{bmatrix} a & b \\\\\\\\ c & c \\\\end{bmatrix} \\\\end{equation} source1234567891011或者使用\\\\(\\LaTeX\\\\)环境：&lt;div&gt;\\\\begin{equation}A =\\\\begin{bmatrix}a &amp; b \\\\\\\\c &amp; c\\\\end{bmatrix}\\\\end{equation}&lt;/div&gt; busuanzi网站分析与live2d的看板娘冲突的问题 有人已提过issue，相关blog；由于加入live2d有两种实现方式，还有一种需要修改源码（官网推荐），教程yingchi’s blog navBar中的svg格式的logo不显示的问题（和footer用的是同一个logo，现在只有footer显示了） 有人已提过issue 给每一个页面加图片(optional) 最后欢迎大家评论与交流~","link":"/2020/06/25/how-to-build-a-blog/"},{"title":"datawhale-零基础入门NLP-Task1","text":"题目理解目标是用多种思路完成天池的NLP新手级题目零基础入门NLP - 新闻文本分类，题目的大意是训练一个模型，对不同的文本段进行分类，分成财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐这十四个类（记作0-13），其中会对输入的文本段做匿名化处理，如下所示： 流程划分由于题目给出的训练用的文本段是匿名化的，无法进行分词操作，将整个比赛流程划分成特征提取和分类模型两个方面，因此在后续任务中会通过四种思路来完成这一题目，分别是： TF-IDF + 机器学习分类器 TF-IDF用于对文本提取特征 FastText FastText是入门款的词向量，由facebook提供 WordVec + 深度学习分类器 WordVec是进阶款的词向量 Bert词向量 Bert是高配款的词向量 测评指标评价标准为类别f1_score的均值，结果越大越好。 对于评测标准的理解评测标准的本质是用来筛选模型的好坏的，而模型的好坏在不同的条件下有不同的标准，因此评测标准也应该是多样的。 在本题中模型的作用是预测一段文本的类别，细化而言，即对于一段文本，判断其是否属于14类中的某一类（例如第3类），如果是模型预测是第3类就是positive，模型预测不是第3类就是negative，再结合实际情况，一共得到四类结果，如下图所示： 在实际中有很多种计算方式： Precision： 公式：$$Precision =\\frac{ True Positive }{ True Positive + False Positive }$$ 理解：这一标准关注的是对于某一类，在所有预测为positive的文本中，在实际中也是positive（即属于true positive）的概率 用途：Precision is a good measure to determine, when the costs of False Positive is high.（当分类器将一个实际negative的样本识别为positive会产生巨大损失时，即对false positive敏感，例如非垃圾邮件被识别成垃圾邮件） Recall： 公式：$$ Recall =\\frac{True Positive}{True Positive+False Negative}$$ 理解：这一标准关注的是对于某一类，在所有实际中为positive的文本中，在预测时也是positive（即属于true positive）的概率，也可以理解成模型对正样例的捕获能力 用途：Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative.（用于当一个正样例被分类错误会带来巨大损失的模型，即对false negative敏感，例如对强传染疾病的分类，将患病病人识别成不患病的） Accuracy： 公式：$$\\mathrm{Accuracy}=\\frac{\\text { True Positive }+\\text { True Negative }}{ \\text { (True Positive }+\\text { False Positive }+\\text { True Negative }+\\text { False Negative })}$$ 理解：计算的是所有样本中分类正确（不论正样例还是负样例）占算有样本的比例 用途：It is most used when all the classes are equally important.（用于所有分类结果都一样重要时） F1_score： 公式：$$\\mathrm{F} 1=\\left(\\frac{\\text { Recall }^{-1}+\\text {Precision }^{-1}}{2}\\right)^{-1} =2 \\times \\frac{ Precision*Recall} {Precision+Recall}$$ 理解：This is the harmonic mean of Precision and Recall and gives a better measure of the incorrectly classified cases than the Accuracy Metric（属于Precision和Recall的平衡点，即对Precision和Recall计算调和平均数） 对于F1_score和Accuracy的比较： Accuracy is used when the True Positives and True negatives are more important while F1-score is used when the False Negatives and False Positives are crucial Accuracy can be used when the class distribution is similar while F1-score is a better metric when there are imbalanced classes as in the above case. In most real-life classification problems, imbalanced class distribution exists and thus F1-score is a better metric to evaluate our model on. Purva HuilgolAccuracy vs. F1-Score 参考[1] Datawhale零基础入门NLP赛事 - Task1官方文档 [2] Accuracy, Precision, Recall or F1? [3] Accuracy vs. F1-Score [3] 图片引用自这里","link":"/2020/07/21/datawhale-NLP-t1/"}],"tags":[{"name":"Hexo,Icarus","slug":"Hexo-Icarus","link":"/tags/Hexo-Icarus/"},{"name":"datawhale","slug":"datawhale","link":"/tags/datawhale/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"}],"categories":[{"name":"博客搭建","slug":"博客搭建","link":"/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"Datawhale学习手记","slug":"Datawhale学习手记","link":"/categories/Datawhale%E5%AD%A6%E4%B9%A0%E6%89%8B%E8%AE%B0/"}]}