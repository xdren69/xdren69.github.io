<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>卷积神经网络——pytorch-learning（四） - Xdren&#039;s blog</title><meta description="这是一篇关于pytorch的系列学习笔记的第四篇，主要学习了如何用pytorch来搭建一个卷积神经网络"><meta property="og:type" content="blog"><meta property="og:title" content="卷积神经网络——pytorch-learning（四）"><meta property="og:url" content="https://xdren69.github.io/2020/08/01/pytorch-learning-4/"><meta property="og:site_name" content="Xdren&#039;s blog"><meta property="og:description" content="这是一篇关于pytorch的系列学习笔记的第四篇，主要学习了如何用pytorch来搭建一个卷积神经网络"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://ufldl.stanford.edu/tutorial/images/Convolution_schematic.gif"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/105832-244617.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/142132-415389.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/142324-256961.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/143138-516563.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/143552-726443.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/04/043500-76666.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/04/043212-614482.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/04/045128-924096.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/103321-54993.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/154655-910069.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/155211-784046.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/151215-789362.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/153045-547791.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/155326-574495.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/155617-685512.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/155649-760652.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/161503-83004.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/162534-820915.png"><meta property="og:image" content="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/164124-300897.png"><meta property="article:published_time" content="2020-07-31T16:38:09.000Z"><meta property="article:modified_time" content="2020-08-11T17:48:27.672Z"><meta property="article:author" content="Xdren"><meta property="article:tag" content="pytorch"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="http://ufldl.stanford.edu/tutorial/images/Convolution_schematic.gif"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://xdren69.github.io/2020/08/01/pytorch-learning-4/"},"headline":"Xdren's blog","image":["http://ufldl.stanford.edu/tutorial/images/Convolution_schematic.gif","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/105832-244617.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/142132-415389.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/142324-256961.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/143138-516563.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/143552-726443.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/04/043500-76666.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/04/043212-614482.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/04/045128-924096.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/103321-54993.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/154655-910069.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/155211-784046.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/151215-789362.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/153045-547791.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/155326-574495.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/155617-685512.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/155649-760652.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/161503-83004.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/162534-820915.png","https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/164124-300897.png"],"datePublished":"2020-07-31T16:38:09.000Z","dateModified":"2020-08-11T17:48:27.672Z","author":{"@type":"Person","name":"Xdren"},"description":"这是一篇关于pytorch的系列学习笔记的第四篇，主要学习了如何用pytorch来搭建一个卷积神经网络"}</script><link rel="canonical" href="https://xdren69.github.io/2020/08/01/pytorch-learning-4/"><link rel="icon" href="/images/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?14e57ad6d6de6c90603b6bea2182917a";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-170595403-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-170595403-1');</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/logo-1.svg" alt="Xdren&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-07-31T16:38:09.000Z" title="2020-07-31T16:38:09.000Z">2020-08-01</time><span class="level-item"><a class="link-muted" href="/categories/pytorch-learning/">pytorch-learning</a></span><span class="level-item">10 分钟 读完 (大约 1519 个字)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">卷积神经网络——pytorch-learning（四）</h1><div class="content"><h2 id="图像形成简述"><a href="#图像形成简述" class="headerlink" title="图像形成简述"></a>图像形成简述</h2><p>一般图像分为两类：</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><ul>
<li><p>栅格图像：图像由像素点组成，一般可以由人工捕获，在相机摄像时，每个像素点都通过一个光学元件来采集——放大后变成马赛克</p>
</li>
<li><p>矢量图像：一般无法人工捕获，由程序生成，相当于一段描述：圆心在哪，半径多少….，一般由程序画出来，而不是现成的——放大不变形</p>
</li>
</ul>
<h2 id="卷积神经网络简述"><a href="#卷积神经网络简述" class="headerlink" title="卷积神经网络简述"></a>卷积神经网络简述</h2><p>使用DNN（全连接神经网络）来进行图像分类时，是将二维图像完全展开成一维图像，只保留了像素间横向的联系，却忽略了纵向的联系。</p>
<p>因此我们引入了卷积神经网络，提取其二维特征，其工作过程是通过黄色的卷积核来提取绿色的图像中的二维特征，随后将特征输出到粉色矩阵中，以便进行下一步的处理。<strong>单通道卷积</strong>的运算过程如下所示：</p>
<p><img src="http://ufldl.stanford.edu/tutorial/images/Convolution_schematic.gif" alt=""></p>
<p>对于卷积核作用的直观理解：检测图像的局部是否满足某一特征，如果满足，则返回一个较大的值；否则返回一个较小的值</p>
<blockquote>
<p>  注意：对于多通道的图像，每次卷积是针对所有的通道来进行的，卷积核应该是三维的，第三个维度的大小应该和通道数相同，因此在讨论<strong>卷积核的大小</strong>时，只考虑二维的大小。如下图所示：</p>
</blockquote>
<p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/105832-244617.png" alt=""></p>
<p>展开后具体如下：</p>
<p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/142132-415389.png" alt=""></p>
<p>压缩后如下所示（卷积时不加padding）：</p>
<p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/142324-256961.png" alt=""></p>
<p>泛化图像的尺寸，以及投影到多个卷积核之后可以得到：</p>
<p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/143138-516563.png" alt=""></p>
<blockquote>
<p>  注意：卷积核的数目与输出结果的通道数相同</p>
</blockquote>
<h3 id="卷积核的相关参数"><a href="#卷积核的相关参数" class="headerlink" title="卷积核的相关参数"></a>卷积核的相关参数</h3><p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/143552-726443.png" alt=""></p>
<p>其中：</p>
<ul>
<li>m是卷积核的个数</li>
<li>n是输入图像的通道数</li>
</ul>
<h3 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h3><p>在图像外层填充0，借此来保证经过卷积计算后的图形与原图形大小保持一致。一般而言，外围填充的0的圈数为</p>
<div>$$\frac{kernel_size}{2}$$</div>

<p>如下图所示：</p>
<p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/04/043500-76666.png" alt=""></p>
<h3 id="stride"><a href="#stride" class="headerlink" title="stride"></a>stride</h3><p>在进行卷积运算时，每一次移动卷积核的距离</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">in_channels, out_channels= <span class="number">5</span>, <span class="number">10</span></span><br><span class="line">width, height = <span class="number">100</span>, <span class="number">100</span></span><br><span class="line">kernel_size = <span class="number">3</span></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">input = torch.randn(batch_size, in_channels, width, height)</span><br><span class="line">conv_layer = torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size)</span><br><span class="line"><span class="comment"># padding参数</span></span><br><span class="line"><span class="comment"># conv_layer = torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1, bias=False)</span></span><br><span class="line"><span class="comment"># stride参数</span></span><br><span class="line"><span class="comment"># conv_layer = torch.nn.Conv2d(1, 1, kernel_size=3, stride=2, bias=False)</span></span><br><span class="line"><span class="comment"># 可以选择自己初始化卷积的权重</span></span><br><span class="line"><span class="comment"># kernel = torch.Tensor([1,2,3,4,5,6,7,8,9]).view(1, 1, 3, 3)</span></span><br><span class="line"><span class="comment"># conv_layer.weight.data = kernel.data</span></span><br><span class="line">output = conv_layer(input)</span><br><span class="line"></span><br><span class="line">print(input.shape)</span><br><span class="line">print(output.shape)</span><br><span class="line">print(conv_layer.weight.shape)</span><br></pre></td></tr></table></figure>

<p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/04/043212-614482.png" alt=""></p>
<h3 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h3><p>可以理解成下采样，用来筛选特征，压缩图像大小。但是特征筛选只在同一个通道内进行；经过pooling之后图像的通道数不改变；在pooling层中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">-   Max Pooling：每次取局部内的最大值</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">import torch</span><br><span class="line">input &#x3D; [3,4,6,5,</span><br><span class="line">2,4,6,8,</span><br><span class="line">1,6,7,8,</span><br><span class="line">9,7,4,6,</span><br><span class="line">]</span><br><span class="line">input &#x3D; torch.Tensor(input).view(1, 1, 4, 4)</span><br><span class="line">maxpooling_layer &#x3D; torch.nn.MaxPool2d(kernel_size&#x3D;2)</span><br><span class="line">output &#x3D; maxpooling_layer(input)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure>

<p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/04/045128-924096.png" alt=""></p>
<h2 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h2><p>在此处我们使用MNIST数据集作为演示，具体网络架构如下：</p>
<p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/03/103321-54993.png" alt=""></p>
<blockquote>
<p>  注意：卷积层和池化层不在意图像的大小，但是线性层在意，需要提前计算</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = torch.nn.Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.pooling = torch.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(<span class="number">320</span>, <span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># Flatten data from (n, 1, 28, 28) to (n, 784)</span></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = F.relu(self.pooling(self.conv1(x)))</span><br><span class="line">        x = F.relu(self.pooling(self.conv2(x)))</span><br><span class="line">        x = x.view(batch_size, <span class="number">-1</span>) <span class="comment"># flatten</span></span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = Net()</span><br></pre></td></tr></table></figure>

<p>对于GPU的使用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选择设备</span></span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"><span class="comment"># 迁移模型</span></span><br><span class="line">model.to(device)</span><br><span class="line"><span class="comment"># 迁移数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(epoch)</span>:</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> enumerate(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data</span><br><span class="line">        <span class="comment"># 这里</span></span><br><span class="line">        inputs, target = inputs.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># forward + backward + update</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">        print(<span class="string">'[%d, %5d] loss: %.3f'</span> % (epoch + <span class="number">1</span>, batch_idx + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">        running_loss = <span class="number">0.0</span></span><br></pre></td></tr></table></figure>



<h2 id="卷积神经网络进阶"><a href="#卷积神经网络进阶" class="headerlink" title="卷积神经网络进阶"></a>卷积神经网络进阶</h2><blockquote>
<p>  以复杂网络GoogLeNet为例子</p>
<p>  <img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/154655-910069.png" alt=""></p>
</blockquote>
<h3 id="对Inception模块进行解释"><a href="#对Inception模块进行解释" class="headerlink" title="对Inception模块进行解释"></a>对Inception模块进行解释</h3><p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/155211-784046.png" alt=""></p>
<h3 id="1-1的卷积核"><a href="#1-1的卷积核" class="headerlink" title="1*1的卷积核"></a>1*1的卷积核</h3><p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/151215-789362.png" alt=""></p>
<p>作用：</p>
<ul>
<li><p>将所有输入通道同一像素点的数值进行加权</p>
</li>
<li><p>改变通道的数目，相比于其他大小的卷积，1*1的卷积在改变通道数目时，计算量较小。对比如下：</p>
<p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/153045-547791.png" alt=""></p>
</li>
</ul>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/155326-574495.png" alt=""></p>
<p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/155617-685512.png" alt=""></p>
<p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/155649-760652.png" alt=""></p>
<blockquote>
<p>   注意：张量的维度表示方式为（B,C,W,H），因此<em>torch.cat</em>操作时dim=1</p>
</blockquote>
<h2 id="卷积的深度及其效果"><a href="#卷积的深度及其效果" class="headerlink" title="卷积的深度及其效果"></a>卷积的深度及其效果</h2><p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/161503-83004.png" alt=""></p>
<blockquote>
<p>  结论：并不是卷积越深，效果越好</p>
<p>  解决方法：使用残差网络（Residual net）</p>
</blockquote>
<h2 id="残差网络（Residual-net）"><a href="#残差网络（Residual-net）" class="headerlink" title="残差网络（Residual net）"></a>残差网络（Residual net）</h2><p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/162534-820915.png" alt=""></p>
<h2 id="搭建网络的建议"><a href="#搭建网络的建议" class="headerlink" title="搭建网络的建议"></a>搭建网络的建议</h2><ol>
<li>逐层搭建，逐层测试，主要测试网络的输入与输出的矩阵的大小</li>
</ol>
<p><img src="https://gitblog-1302688916.cos.ap-beijing.myqcloud.com/cs224n/202008/11/164124-300897.png" alt=""></p>
<h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><p>[1] <a href="https://www.bilibili.com/video/BV1Y7411d7Ys">河北工业大学刘洪普老师的视频教程</a></p>
<p>[2] <a href="">He K, Zhang X, Ren S, et al. Identity Mappings in Deep Residual Networks</a></p>
<p>[3] <a href="">Huang G, Liu Z, Laurens V D M, et al. Densely Connected Convolutional Networks</a></p>
</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/pytorch/">pytorch</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5ef30ed0b71a170012eece9c&amp;product=inline-share-buttons" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/09/07/information-retrieval-ch1/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">chap 1-Boolean retrieval</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/08/01/pytorch-learning-3/"><span class="level-item">Logistic回归与多分类问题——pytorch-learning（三）</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://xdren69.github.io/2020/08/01/pytorch-learning-4/';
            this.page.identifier = '2020/08/01/pytorch-learning-4/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'myblog-57tixcutzr' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/images/avatar.png" alt="xdren"></figure><p class="title is-size-4 is-block line-height-inherit">xdren</p><p class="is-size-6 is-block">master student in computer science</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">23</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">5</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/xdren69" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/xdren69"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="is-flex" href="#图像形成简述"><span class="mr-2">1</span><span>图像形成简述</span></a></li><li><a class="is-flex" href="#卷积神经网络简述"><span class="mr-2">2</span><span>卷积神经网络简述</span></a><ul class="menu-list"><li><a class="is-flex" href="#卷积核的相关参数"><span class="mr-2">2.1</span><span>卷积核的相关参数</span></a></li><li><a class="is-flex" href="#padding"><span class="mr-2">2.2</span><span>padding</span></a></li><li><a class="is-flex" href="#stride"><span class="mr-2">2.3</span><span>stride</span></a></li><li><a class="is-flex" href="#Pooling"><span class="mr-2">2.4</span><span>Pooling</span></a></li></ul></li><li><a class="is-flex" href="#代码示例"><span class="mr-2">3</span><span>代码示例</span></a></li><li><a class="is-flex" href="#卷积神经网络进阶"><span class="mr-2">4</span><span>卷积神经网络进阶</span></a><ul class="menu-list"><li><a class="is-flex" href="#对Inception模块进行解释"><span class="mr-2">4.1</span><span>对Inception模块进行解释</span></a></li><li><a class="is-flex" href="#1-1的卷积核"><span class="mr-2">4.2</span><span>1*1的卷积核</span></a></li><li><a class="is-flex" href="#代码实现"><span class="mr-2">4.3</span><span>代码实现</span></a></li></ul></li><li><a class="is-flex" href="#卷积的深度及其效果"><span class="mr-2">5</span><span>卷积的深度及其效果</span></a></li><li><a class="is-flex" href="#残差网络（Residual-net）"><span class="mr-2">6</span><span>残差网络（Residual net）</span></a></li><li><a class="is-flex" href="#搭建网络的建议"><span class="mr-2">7</span><span>搭建网络的建议</span></a></li><li><a class="is-flex" href="#引用"><span class="mr-2">8</span><span>引用</span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile is-mobile" href="http://github.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">GitHub</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Datawhale%E5%AD%A6%E4%B9%A0%E6%89%8B%E8%AE%B0/"><span class="level-start"><span class="level-item">Datawhale学习手记</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/deep-learning/"><span class="level-start"><span class="level-item">deep learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/information-retrieval/"><span class="level-start"><span class="level-item">information retrieval</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/pytorch-learning/"><span class="level-start"><span class="level-item">pytorch-learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"><span class="level-start"><span class="level-item">博客搭建</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"><span class="level-start"><span class="level-item">环境配置</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-10-18T02:57:27.000Z">2020-10-18</time></p><p class="title is-6"><a class="link-muted" href="/2020/10/18/learning-Bert/">对于Bert模型的学习</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/deep-learning/">deep learning</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-10-13T02:02:07.000Z">2020-10-13</time></p><p class="title is-6"><a class="link-muted" href="/2020/10/13/learning-transformer/">对于transformer的学习与认识</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/deep-learning/">deep learning</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-10-03T02:21:50.000Z">2020-10-03</time></p><p class="title is-6"><a class="link-muted" href="/2020/10/03/cuda-ubuntu-install/">ubuntu16.04安装cuda和cudnn</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/">环境配置</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-09-19T07:30:19.000Z">2020-09-19</time></p><p class="title is-6"><a class="link-muted" href="/2020/09/19/information-retrieval-ch10/">chap 10-XML retrieval</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/information-retrieval/">information retrieval</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-09-19T07:30:12.000Z">2020-09-19</time></p><p class="title is-6"><a class="link-muted" href="/2020/09/19/information-retrieval-ch9/">chap 9-Relevance feedback and query expansion</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/information-retrieval/">information retrieval</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/10/"><span class="level-start"><span class="level-item">十月 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/09/"><span class="level-start"><span class="level-item">九月 2020</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/08/"><span class="level-start"><span class="level-item">八月 2020</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">七月 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">六月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Hexo-Icarus/"><span class="tag">Hexo,Icarus</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cuda/"><span class="tag">cuda</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/datawhale/"><span class="tag">datawhale</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag is-grey-lightest">4</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/logo-1.svg" alt="Xdren&#039;s blog" height="28"></a><p class="size-small"><span>&copy; 2020 Xdren</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://xdren69.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":200,"height":400},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body></html>